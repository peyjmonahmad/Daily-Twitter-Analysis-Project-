{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules necessary for interaction with Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import cnfg\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from pymongo import MongoClient\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API authentication - Consumer API Keys and Access Token.  These 4 keys are given when twitter gives you access to their API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler('xxxx',\n",
    "                           'xxxx')\n",
    "auth.set_access_token('xxxx',\n",
    "                      'xxxx')\n",
    "\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store tweets in a Mongo Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Intialize Mongo Database\n",
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2fri_db',\n",
       " 'acosta_db',\n",
       " 'admin',\n",
       " 'avenatti_db',\n",
       " 'config',\n",
       " 'fox_db',\n",
       " 'fri_db',\n",
       " 'last_fri_db',\n",
       " 'late_db',\n",
       " 'local',\n",
       " 'more_sat',\n",
       " 'new_db',\n",
       " 'sat_db',\n",
       " 'sat_late',\n",
       " 'thurs_db',\n",
       " 'thurs_test',\n",
       " 'twitter_database',\n",
       " 'wed_db']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View list of available databases\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how tweets were collected for each database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_db = client['twitter_database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize tweet collector\n",
    "twitter_db_tweets = twitter_db.tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test to collect a tweet from a username, and insert into one of our databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = '@realDonaldTrump'\n",
    "tweets = tweepy.Cursor(api.user_timeline, screen_name=username, tweet_mode='extended').items()\n",
    "tweet_dict_list = []\n",
    "\n",
    "for t in tqdm(tweets):\n",
    "    d = {}\n",
    "    d['created_at'] = t.created_at\n",
    "    d['favorite_count'] = t.favorite_count\n",
    "    d['retweet_count'] = t.retweet_count\n",
    "    d['full_text'] = t.full_text\n",
    "    d['screen_name'] = t.user.screen_name\n",
    "    \n",
    "    tweet_dict_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Insert first item from above into twitter_db database\n",
    "twitter_db_tweets.insert_one(tweet_dict_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to use our stream listener. This allows us to grab live tweets from any given key word search on twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        data = json.loads(data)\n",
    "        \n",
    "        # Pull the fields we want, and throw it into our mongodb database\n",
    "        if data['lang'] == 'en':\n",
    "            tweet_document = {}\n",
    "\n",
    "            tweet_document['created_at'] = data['created_at']\n",
    "            tweet_document['favorite_count'] = data['favorite_count']\n",
    "            tweet_document['retweet_count'] = data['retweet_count']\n",
    "\n",
    "            #Get full text if it is an extended tweet\n",
    "            if 'extended_tweet' in data.keys():\n",
    "                tweet_document['text'] = data['extended_tweet']['full_text']\n",
    "            else:\n",
    "                tweet_document['text'] = data['text']\n",
    "\n",
    "            tweet_document['screen_name'] = data['user']['screen_name']\n",
    "\n",
    "            text = TextBlob(tweet_document['text']).sentiment\n",
    "\n",
    "            tweet_document['sentiment'] = text.polarity\n",
    "            tweet_document['subjectivity'] = text.subjectivity\n",
    "\n",
    "           # print(tweet_document)\n",
    "           # print('\\n')\n",
    "            twitter_db_tweets.insert_one(tweet_document)\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start up the twitterStream\n",
    "twitterStream = Stream(auth,listener())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify by getting all tweets containing the following key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = twitterStream.filter(track=['cnn','fox_news','wall street journal','@economist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Collect all the tweets, sorted by time created\n",
    "tweet_collect= twitter_db['tweets'].find().sort([('created_at',-1)]).limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store the collection into a list\n",
    "tweet_list = [item for item in tweet_collect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a Pandas data frame from the list\n",
    "tweet_df = pd.DataFrame(tweet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe that has all the information needed to move forward with deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
